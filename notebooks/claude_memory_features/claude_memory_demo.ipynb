{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claude Memory on Amazon Bedrock\n",
    "\n",
    "This notebook demonstrates Claude's native memory feature across different chat sessions on Amazon Bedrock.\n",
    "\n",
    "## Key Concepts:\n",
    "- Starting with Claude Sonnet 4.5, and include support for previous model releases, Claude can store persistent memories using its built-in memory tool\n",
    "- Memories persist across different chat sessions\n",
    "- The client only needs to handle tool use/result exchange\n",
    "- Claude directs the memory storage and retrieval, and storage and retrieval is done on the client side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Minimal Client Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Minimal client setup complete\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "from datetime import datetime\n",
    "from botocore.config import Config\n",
    "\n",
    "config = Config(\n",
    "   retries = {\n",
    "      'total_max_attempts': 1000,\n",
    "      'mode': 'standard'\n",
    "   }\n",
    ")\n",
    "\n",
    "# AWS session setup\n",
    "session = boto3.session.Session()\n",
    "bedrock_rt = session.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Simple memory storage for handling tool results\n",
    "memory_store = {}\n",
    "\n",
    "def handle_memory_tool(tool_input):\n",
    "    \"\"\"Minimal handler for Claude Sonnet 4.5's memory tool requests\"\"\"\n",
    "    command = tool_input.get('command')\n",
    "    path = tool_input.get('path', '')\n",
    "    \n",
    "    if command == 'view':\n",
    "        if path == '/memories':\n",
    "            return {'memories': list(memory_store.values())}\n",
    "        elif path.startswith('/memories/'):\n",
    "            key = path.split('/')[-1]\n",
    "            return {'memory': memory_store.get(key, {'error': 'not found'})}\n",
    "    \n",
    "    elif command == 'create':\n",
    "        key = path.split('/')[-1] if '/' in path else f\"mem_{len(memory_store)}\"\n",
    "        memory_store[key] = {\n",
    "            'path': path,\n",
    "            'content': tool_input.get('file_text', ''),\n",
    "            'created': datetime.now().isoformat()\n",
    "        }\n",
    "        return {'success': True, 'created': key}\n",
    "    \n",
    "    return {'status': 'handled', 'command': command}\n",
    "\n",
    "print(\"✅ Minimal client setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 1: Ask Claude Sonnet 4.5 to Remember Information\n",
    "\n",
    "First, we'll have a conversation where Claude Sonnet 4.5 stores memories about us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chat function ready\n"
     ]
    }
   ],
   "source": [
    "def chat_with_claude(message, conversation_history=None):\n",
    "    \"\"\"Send a message to Claude Sonnet 4.5 and handle any tool use\"\"\"\n",
    "    messages = conversation_history or []\n",
    "    \n",
    "    # Add user message\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": message}]\n",
    "    })\n",
    "    \n",
    "    print(f\"👤 User: {message}\\n\")\n",
    "    \n",
    "    # Keep handling tool uses until Claude Sonnet 4.5 stops requesting them\n",
    "    max_iterations = 5  # Safety limit\n",
    "    iteration = 0\n",
    "    \n",
    "    while iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        \n",
    "        # Prepare request body\n",
    "        body = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"anthropic_beta\": [\"context-management-2025-06-27\"],\n",
    "            \"tools\": [{\n",
    "                \"type\": \"memory_20250818\",\n",
    "                \"name\": \"memory\"\n",
    "            }],\n",
    "            \"max_tokens\": 4000,\n",
    "            \"messages\": messages,\n",
    "        }\n",
    "        \n",
    "        # Send to Claude Sonnet 4.5\n",
    "        response = bedrock_rt.invoke_model(\n",
    "            modelId=\"us.anthropic.claude-sonnet-4-5-20250929-v1:0\",\n",
    "            body=json.dumps(body)\n",
    "        )\n",
    "        result = json.loads(response[\"body\"].read())\n",
    "        \n",
    "        # Track if we need to handle tool use\n",
    "        has_tool_use = False\n",
    "        tool_uses = []\n",
    "        \n",
    "        # Process response\n",
    "        for content in result.get('content', []):\n",
    "            if content['type'] == 'text':\n",
    "                print(f\"🤖 Claude: {content['text']}\\n\")\n",
    "            \n",
    "            elif content['type'] == 'tool_use':\n",
    "                has_tool_use = True\n",
    "                tool_uses.append(content)\n",
    "                print(f\"🔧 Claude uses memory tool: {content['input'].get('command', 'unknown')}\")\n",
    "                print(f\"   Path: {content['input'].get('path', 'N/A')}\")\n",
    "                if content['input'].get('file_text'):\n",
    "                    print(f\"   Creating memory file...\\n\")\n",
    "        \n",
    "        # Add Claude's response to conversation\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": result['content']\n",
    "        })\n",
    "        \n",
    "        # If no tool use, we're done\n",
    "        if not has_tool_use:\n",
    "            break\n",
    "        \n",
    "        # Handle all tool uses\n",
    "        tool_results = []\n",
    "        for tool_use in tool_uses:\n",
    "            tool_result = handle_memory_tool(tool_use['input'])\n",
    "            tool_results.append({\n",
    "                \"type\": \"tool_result\",\n",
    "                \"tool_use_id\": tool_use['id'],\n",
    "                \"content\": json.dumps(tool_result)\n",
    "            })\n",
    "        \n",
    "        # Add tool results to conversation\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": tool_results\n",
    "        })\n",
    "        \n",
    "        # Continue loop to get Claude's next response\n",
    "    \n",
    "    return messages\n",
    "\n",
    "print(\"✅ Chat function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SESSION 1: Teaching Claude Sonnet 4.5 About Me\n",
      "============================================================\n",
      "\n",
      "👤 User: Hi Claude! Please remember these important things about me: 1) I'm a Python developer working on machine learning projects, 2) I prefer using VSCode with dark theme, 3) My favorite Python libraries are numpy, pandas, and scikit-learn, 4) I'm currently learning about LLM memory systems like yours!\n",
      "\n",
      "🔧 Claude uses memory tool: view\n",
      "   Path: /memories\n",
      "🔧 Claude uses memory tool: create\n",
      "   Path: /memories/user_profile.txt\n",
      "   Creating memory file...\n",
      "\n",
      "🤖 Claude: \n",
      "\n",
      "Perfect! I've saved all that important information about you to my memory. Here's what I've recorded:\n",
      "\n",
      "✅ **Professional**: Python developer working on ML projects\n",
      "✅ **Dev Environment**: VSCode with dark theme\n",
      "✅ **Favorite Libraries**: numpy, pandas, and scikit-learn\n",
      "✅ **Current Learning**: LLM memory systems\n",
      "\n",
      "I'll remember these details for our future conversations! It's great that you're learning about LLM memory systems - you're literally experiencing one right now. I use a file-based memory system where I can store and retrieve information between our interactions. Feel free to ask me anything about ML, Python, or how this memory system works!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SESSION 1: Teaching Claude Sonnet 4.5 About Me\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# First conversation - Claude Sonnet 4.5 will remember this\n",
    "conversation1 = chat_with_claude(\n",
    "    \"Hi Claude! Please remember these important things about me: \"\n",
    "    \"1) I'm a Python developer working on machine learning projects, \"\n",
    "    \"2) I prefer using VSCode with dark theme, \"\n",
    "    \"3) My favorite Python libraries are numpy, pandas, and scikit-learn, \"\n",
    "    \"4) I'm currently learning about LLM memory systems like yours!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Local memory store after Session 1:\n",
      "========================================\n",
      "Key: user_profile.txt\n",
      "Path: /memories/user_profile.txt\n",
      "Content preview: USER PROFILE\n",
      "============\n",
      "\n",
      "Professional Background:\n",
      "- Python developer\n",
      "- Works on machine learning projects\n",
      "\n",
      "Development Environment:\n",
      "- Preferred IDE: VSCode\n",
      "- Theme preference: Dark theme\n",
      "\n",
      "Favorite P...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check what was stored locally\n",
    "print(\"📦 Local memory store after Session 1:\")\n",
    "print(\"=\" * 40)\n",
    "for key, value in memory_store.items():\n",
    "    print(f\"Key: {key}\")\n",
    "    print(f\"Path: {value.get('path', 'N/A')}\")\n",
    "    if value.get('content'):\n",
    "        print(f\"Content preview: {value['content'][:200]}...\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 2: New Chat - Claude Sonnet 4.5 Recalls Information\n",
    "\n",
    "Now we start a **completely new conversation** without any prior context, and ask Claude Sonnet 4.5 what it knows about us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SESSION 2: New Chat - Testing Memory Recall\n",
      "============================================================\n",
      "\n",
      "🔄 Starting fresh conversation (no prior context)\n",
      "\n",
      "👤 User: What do you remember about me and my interests?\n",
      "\n",
      "🔧 Claude uses memory tool: view\n",
      "   Path: /memories\n",
      "🤖 Claude: \n",
      "\n",
      "Based on my memory, here's what I know about you:\n",
      "\n",
      "**Professional Background:**\n",
      "- You're a Python developer who works on machine learning projects\n",
      "\n",
      "**Development Preferences:**\n",
      "- You use VSCode as your preferred IDE\n",
      "- You like dark themes\n",
      "\n",
      "**Favorite Tools:**\n",
      "- Your go-to Python libraries are numpy, pandas, and scikit-learn\n",
      "\n",
      "**Current Interests:**\n",
      "- You're learning about LLM memory systems\n",
      "- You're interested in understanding how memory works in AI assistants\n",
      "\n",
      "Is there anything you'd like to add or update about yourself?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SESSION 2: New Chat - Testing Memory Recall\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n🔄 Starting fresh conversation (no prior context)\\n\")\n",
    "\n",
    "# Completely new conversation - Claude Sonnet 4.5 should remember from before\n",
    "conversation2 = chat_with_claude(\n",
    "    \"What do you remember about me and my interests?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Testing specific recall...\n",
      "============================================================\n",
      "\n",
      "👤 User: Based on what you know about me, what Python library would you recommend for a data visualization project?\n",
      "\n",
      "🔧 Claude uses memory tool: view\n",
      "   Path: /memories\n",
      "🤖 Claude: \n",
      "\n",
      "Based on what I know about you, I'd recommend **Matplotlib** or **Seaborn** for your data visualization project. Here's why:\n",
      "\n",
      "**Primary recommendation: Matplotlib**\n",
      "- It integrates seamlessly with **NumPy** and **Pandas** (your favorite libraries!)\n",
      "- Essential for ML projects - perfect for visualizing model performance, training curves, feature distributions, etc.\n",
      "- Very versatile and powerful for scientific/statistical visualizations\n",
      "- Industry standard in the ML/data science community\n",
      "\n",
      "**Secondary recommendation: Seaborn**\n",
      "- Built on top of Matplotlib\n",
      "- Works beautifully with Pandas DataFrames\n",
      "- Great for statistical visualizations common in ML (correlation matrices, distributions, pair plots)\n",
      "- More aesthetically pleasing defaults out of the box\n",
      "- Less code for complex statistical plots\n",
      "\n",
      "**Honorable mention: Plotly**\n",
      "- If you need interactive visualizations\n",
      "- Great for web-based dashboards or exploratory data analysis\n",
      "- Works well in Jupyter notebooks (which I assume you might use given your ML work)\n",
      "\n",
      "Given your background in machine learning with scikit-learn, numpy, and pandas, **Matplotlib** would be my top choice as it's the foundation most ML practitioners use, with **Seaborn** as a complementary library for when you want more sophisticated statistical plots with less code.\n",
      "\n",
      "Would you like specific recommendations for your particular visualization use case?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Another query in new session\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Testing specific recall...\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "conversation3 = chat_with_claude(\n",
    "    \"Based on what you know about me, what Python library would you recommend \"\n",
    "    \"for a data visualization project?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 3: Memory-Based Assistance\n",
    "\n",
    "Now let's demonstrate Claude Sonnet 4.5 using stored memories to provide personalized help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SESSION 3: Personalized Code Generation\n",
      "============================================================\n",
      "\n",
      "🎯 Claude Sonnet 4.5 will use memories to generate personalized code\n",
      "\n",
      "👤 User: Can you write me a Python script template that matches my preferences? Include imports for my favorite libraries and add appropriate comments.\n",
      "\n",
      "🤖 Claude: I'll check my memory first to see if I have any information about your preferences and favorite libraries.\n",
      "\n",
      "🔧 Claude uses memory tool: view\n",
      "   Path: /memories\n",
      "🤖 Claude: \n",
      "\n",
      "Perfect! I found your preferences. Let me create a Python script template that matches your profile with your favorite libraries (numpy, pandas, and scikit-learn).\n",
      "\n",
      "```python\n",
      "#!/usr/bin/env python3\n",
      "\"\"\"\n",
      "Script Template\n",
      "================\n",
      "\n",
      "Description:\n",
      "    [Add your script description here]\n",
      "\n",
      "Author: [Your Name]\n",
      "Date: [Date]\n",
      "\"\"\"\n",
      "\n",
      "# Standard library imports\n",
      "import os\n",
      "import sys\n",
      "from pathlib import Path\n",
      "from typing import List, Dict, Tuple, Optional, Any\n",
      "\n",
      "# Data manipulation and numerical computing\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# Machine learning\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.metrics import accuracy_score, classification_report\n",
      "\n",
      "# Optional: Add other commonly used sklearn imports as needed\n",
      "# from sklearn.linear_model import LogisticRegression\n",
      "# from sklearn.ensemble import RandomForestClassifier\n",
      "# from sklearn.pipeline import Pipeline\n",
      "\n",
      "\n",
      "def load_data(filepath: str) -> pd.DataFrame:\n",
      "    \"\"\"\n",
      "    Load data from file.\n",
      "    \n",
      "    Args:\n",
      "        filepath: Path to the data file\n",
      "        \n",
      "    Returns:\n",
      "        DataFrame containing the loaded data\n",
      "    \"\"\"\n",
      "    pass\n",
      "\n",
      "\n",
      "def preprocess_data(df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
      "    \"\"\"\n",
      "    Preprocess and prepare data for modeling.\n",
      "    \n",
      "    Args:\n",
      "        df: Input DataFrame\n",
      "        \n",
      "    Returns:\n",
      "        Tuple of (features, targets)\n",
      "    \"\"\"\n",
      "    pass\n",
      "\n",
      "\n",
      "def train_model(X_train: np.ndarray, y_train: np.ndarray):\n",
      "    \"\"\"\n",
      "    Train the machine learning model.\n",
      "    \n",
      "    Args:\n",
      "        X_train: Training features\n",
      "        y_train: Training targets\n",
      "        \n",
      "    Returns:\n",
      "        Trained model\n",
      "    \"\"\"\n",
      "    pass\n",
      "\n",
      "\n",
      "def evaluate_model(model, X_test: np.ndarray, y_test: np.ndarray) -> Dict[str, Any]:\n",
      "    \"\"\"\n",
      "    Evaluate model performance.\n",
      "    \n",
      "    Args:\n",
      "        model: Trained model\n",
      "        X_test: Test features\n",
      "        y_test: Test targets\n",
      "        \n",
      "    Returns:\n",
      "        Dictionary containing evaluation metrics\n",
      "    \"\"\"\n",
      "    pass\n",
      "\n",
      "\n",
      "def main():\n",
      "    \"\"\"\n",
      "    Main execution function.\n",
      "    \"\"\"\n",
      "    # Configuration\n",
      "    DATA_PATH = \"data/your_data.csv\"\n",
      "    RANDOM_STATE = 42\n",
      "    TEST_SIZE = 0.2\n",
      "    \n",
      "    # Load data\n",
      "    print(\"Loading data...\")\n",
      "    df = load_data(DATA_PATH)\n",
      "    \n",
      "    # Preprocess\n",
      "    print(\"Preprocessing data...\")\n",
      "    X, y = preprocess_data(df)\n",
      "    \n",
      "    # Split data\n",
      "    X_train, X_test, y_train, y_test = train_test_split(\n",
      "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
      "    )\n",
      "    \n",
      "    # Train model\n",
      "    print(\"Training model...\")\n",
      "    model = train_model(X_train, y_train)\n",
      "    \n",
      "    # Evaluate\n",
      "    print(\"Evaluating model...\")\n",
      "    results = evaluate_model(model, X_test, y_test)\n",
      "    print(f\"Results: {results}\")\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "\n",
      "This template includes:\n",
      "\n",
      "✅ **Your favorite libraries**: numpy, pandas, and scikit-learn  \n",
      "✅ **ML-focused structure**: Functions for loading, preprocessing, training, and evaluating models  \n",
      "✅ **Type hints**: For better code clarity and IDE support (great for VSCode!)  \n",
      "✅ **Comprehensive comments**: Docstrings for all functions  \n",
      "✅ **Common ML workflow**: train_test_split, preprocessing patterns, and evaluation  \n",
      "✅ **Professional structure**: Modular functions and a clean main() entry point\n",
      "\n",
      "Feel free to customize the specific sklearn components (uncomment the imports you need) based on your project requirements!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SESSION 3: Personalized Code Generation\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n🎯 Claude Sonnet 4.5 will use memories to generate personalized code\\n\")\n",
    "\n",
    "conversation4 = chat_with_claude(\n",
    "    \"Can you write me a Python script template that matches my preferences? \"\n",
    "    \"Include imports for my favorite libraries and add appropriate comments.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating Memory Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SESSION 4: Updating Memories\n",
      "============================================================\n",
      "\n",
      "👤 User: Update your memory about me: I've recently started using PyTorch for deep learning and I'm also interested in transformer models. Also, I now prefer using Jupyter Lab instead of just VSCode.\n",
      "\n",
      "🔧 Claude uses memory tool: view\n",
      "   Path: /memories\n",
      "🔧 Claude uses memory tool: str_replace\n",
      "   Path: /memories/user_profile.txt\n",
      "🤖 Claude: \n",
      "\n",
      "Perfect! I've updated my memory about you. Here's what I've recorded:\n",
      "\n",
      "**New additions:**\n",
      "- You've recently started using **PyTorch** for deep learning\n",
      "- You're interested in **transformer models**\n",
      "- You now prefer using **Jupyter Lab** instead of just VSCode\n",
      "\n",
      "These updates have been added to your profile, so I'll remember your focus on PyTorch and transformers, as well as your IDE preference for future conversations!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SESSION 4: Updating Memories\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "conversation5 = chat_with_claude(\n",
    "    \"Update your memory about me: I've recently started using PyTorch for deep learning \"\n",
    "    \"and I'm also interested in transformer models. Also, I now prefer using Jupyter Lab \"\n",
    "    \"instead of just VSCode.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Verifying memory update...\n",
      "============================================================\n",
      "\n",
      "👤 User: What do you know about my deep learning interests?\n",
      "\n",
      "🤖 Claude: I'll check my memory to see what I know about your deep learning interests.\n",
      "\n",
      "🔧 Claude uses memory tool: view\n",
      "   Path: /memories\n",
      "🤖 Claude: \n",
      "\n",
      "Based on my memory, I can see that you're a Python developer who works on machine learning projects, but I don't have specific information about **deep learning interests** recorded yet. \n",
      "\n",
      "What I do know is:\n",
      "- You work on machine learning projects\n",
      "- Your favorite Python libraries include numpy, pandas, and scikit-learn\n",
      "- You're currently learning about LLM memory systems and how memory works in AI assistants\n",
      "- You use VSCode with a dark theme\n",
      "\n",
      "However, I don't have detailed information about specific deep learning topics, frameworks (like PyTorch or TensorFlow), architectures, or applications that interest you. Would you like to tell me more about your deep learning interests so I can keep track of them?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify the update worked\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Verifying memory update...\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "conversation6 = chat_with_claude(\n",
    "    \"What do you know about my deep learning interests?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Memory Usage Statistics\n",
      "========================================\n",
      "Total memory operations: 1\n",
      "Memory keys: ['user_profile.txt']\n",
      "\n",
      "📅 Memory Timeline:\n",
      "  2025-09-29T10:35:54 - user_profile.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"📊 Memory Usage Statistics\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total memory operations: {len(memory_store)}\")\n",
    "print(f\"Memory keys: {list(memory_store.keys())}\")\n",
    "print()\n",
    "\n",
    "# Show timeline of memory creation\n",
    "print(\"📅 Memory Timeline:\")\n",
    "for key, value in memory_store.items():\n",
    "    created = value.get('created', 'Unknown')\n",
    "    print(f\"  {created[:19]} - {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Cross-Session Context Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing memory persistence across sessions\n",
      "\n",
      "Session A: Storing information...\n",
      "👤 User: Remember this secret project code: ALPHA-2024-ML\n",
      "\n",
      "🔧 Claude uses memory tool: view\n",
      "   Path: /memories\n",
      "🔧 Claude uses memory tool: create\n",
      "   Path: /memories/secret_codes.txt\n",
      "   Creating memory file...\n",
      "\n",
      "🤖 Claude: \n",
      "\n",
      "I've recorded the secret project code **ALPHA-2024-ML** in my memory. I'll remember this for you!\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "Session B: New session, retrieving information...\n",
      "👤 User: What was the secret project code I told you about?\n",
      "\n",
      "🔧 Claude uses memory tool: view\n",
      "   Path: /memories\n",
      "🤖 Claude: \n",
      "\n",
      "Based on my memory, the secret project code you told me about is **ALPHA-2024-ML**.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_memory_persistence():\n",
    "    \"\"\"Test that Claude Sonnet 4.5 remembers across completely independent sessions\"\"\"\n",
    "    \n",
    "    print(\"🧪 Testing memory persistence across sessions\\n\")\n",
    "    \n",
    "    # Session A: Store a secret code\n",
    "    print(\"Session A: Storing information...\")\n",
    "    chat_with_claude(\"Remember this secret project code: ALPHA-2024-ML\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 40 + \"\\n\")\n",
    "    \n",
    "    # Session B: Completely new, retrieve the code\n",
    "    print(\"Session B: New session, retrieving information...\")\n",
    "    chat_with_claude(\"What was the secret project code I told you about?\")\n",
    "\n",
    "test_memory_persistence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Example: Building a Personalized Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PRACTICAL DEMO: Personalized ML Project Setup\n",
      "============================================================\n",
      "\n",
      "👤 User: Based on everything you know about me, create a project structure for a new machine learning project. Include a requirements.txt with my preferred libraries, a main.py template with my coding style, and a README that reflects my interests.\n",
      "\n",
      "🤖 Claude: I'll check my memory to see what I know about you, then create a personalized project structure.\n",
      "\n",
      "🔧 Claude uses memory tool: view\n",
      "   Path: /memories\n",
      "🤖 Claude: \n",
      "\n",
      "Great! Based on your profile, I can see you're a Python developer working on ML projects who prefers numpy, pandas, and scikit-learn. You use VSCode with a dark theme and are interested in LLM memory systems. Let me create a personalized ML project structure for you.\n",
      "\n",
      "🔧 Claude uses memory tool: str_replace\n",
      "   Path: /memories/user_profile.txt\n",
      "🤖 Claude: \n",
      "\n",
      "Now, let me create your personalized ML project structure:\n",
      "\n",
      "## Project Structure Created:\n",
      "\n",
      "### 1. **requirements.txt** - Your preferred libraries\n",
      "```txt\n",
      "# Core ML Libraries\n",
      "numpy>=1.24.0\n",
      "pandas>=2.0.0\n",
      "scikit-learn>=1.3.0\n",
      "\n",
      "# Data Visualization\n",
      "matplotlib>=3.7.0\n",
      "seaborn>=0.12.0\n",
      "\n",
      "# Jupyter Support (for experimentation)\n",
      "jupyter>=1.0.0\n",
      "ipykernel>=6.25.0\n",
      "\n",
      "# Utilities\n",
      "python-dotenv>=1.0.0\n",
      "tqdm>=4.65.0\n",
      "\n",
      "# Code Quality\n",
      "black>=23.0.0\n",
      "flake8>=6.0.0\n",
      "pytest>=7.4.0\n",
      "```\n",
      "\n",
      "### 2. **main.py** - Template with clean Python style\n",
      "```python\n",
      "\"\"\"\n",
      "Machine Learning Project Template\n",
      "Author: Your Name\n",
      "Project Code: ALPHA-2024-ML\n",
      "\"\"\"\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from typing import Tuple, Optional\n",
      "import logging\n",
      "\n",
      "# Configure logging\n",
      "logging.basicConfig(\n",
      "    level=logging.INFO,\n",
      "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
      ")\n",
      "logger = logging.getLogger(__name__)\n",
      "\n",
      "\n",
      "class MLPipeline:\n",
      "    \"\"\"\n",
      "    A flexible ML pipeline for data processing and model training.\n",
      "    \"\"\"\n",
      "    \n",
      "    def __init__(self, random_state: int = 42):\n",
      "        \"\"\"\n",
      "        Initialize the ML pipeline.\n",
      "        \n",
      "        Args:\n",
      "            random_state: Random seed for reproducibility\n",
      "        \"\"\"\n",
      "        self.random_state = random_state\n",
      "        self.scaler = StandardScaler()\n",
      "        self.model = None\n",
      "        logger.info(\"ML Pipeline initialized\")\n",
      "    \n",
      "    def load_data(self, filepath: str) -> pd.DataFrame:\n",
      "        \"\"\"\n",
      "        Load data from file.\n",
      "        \n",
      "        Args:\n",
      "            filepath: Path to the data file\n",
      "            \n",
      "        Returns:\n",
      "            Loaded DataFrame\n",
      "        \"\"\"\n",
      "        logger.info(f\"Loading data from {filepath}\")\n",
      "        df = pd.read_csv(filepath)\n",
      "        logger.info(f\"Data loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
      "        return df\n",
      "    \n",
      "    def preprocess_data(\n",
      "        self, \n",
      "        df: pd.DataFrame, \n",
      "        target_col: str\n",
      "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
      "        \"\"\"\n",
      "        Preprocess the data for training.\n",
      "        \n",
      "        Args:\n",
      "            df: Input DataFrame\n",
      "            target_col: Name of the target column\n",
      "            \n",
      "        Returns:\n",
      "            Tuple of (X, y) arrays\n",
      "        \"\"\"\n",
      "        logger.info(\"Preprocessing data\")\n",
      "        \n",
      "        # Separate features and target\n",
      "        X = df.drop(columns=[target_col]).values\n",
      "        y = df[target_col].values\n",
      "        \n",
      "        # Handle missing values if any\n",
      "        if np.isnan(X).any():\n",
      "            logger.warning(\"Missing values detected, applying mean imputation\")\n",
      "            X = np.nan_to_num(X, nan=np.nanmean(X))\n",
      "        \n",
      "        return X, y\n",
      "    \n",
      "    def split_data(\n",
      "        self, \n",
      "        X: np.ndarray, \n",
      "        y: np.ndarray, \n",
      "        test_size: float = 0.2\n",
      "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
      "        \"\"\"\n",
      "        Split data into training and testing sets.\n",
      "        \n",
      "        Args:\n",
      "            X: Feature matrix\n",
      "            y: Target vector\n",
      "            test_size: Proportion of data for testing\n",
      "            \n",
      "        Returns:\n",
      "            Tuple of (X_train, X_test, y_train, y_test)\n",
      "        \"\"\"\n",
      "        logger.info(f\"Splitting data with test_size={test_size}\")\n",
      "        return train_test_split(\n",
      "            X, y, \n",
      "            test_size=test_size, \n",
      "            random_state=self.random_state\n",
      "        )\n",
      "    \n",
      "    def train(self, X_train: np.ndarray, y_train: np.ndarray) -> None:\n",
      "        \"\"\"\n",
      "        Train the model.\n",
      "        \n",
      "        Args:\n",
      "            X_train: Training features\n",
      "            y_train: Training targets\n",
      "        \"\"\"\n",
      "        logger.info(\"Training model...\")\n",
      "        \n",
      "        # Scale features\n",
      "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
      "        \n",
      "        # TODO: Initialize and train your model here\n",
      "        # Example: self.model = SomeModel()\n",
      "        # self.model.fit(X_train_scaled, y_train)\n",
      "        \n",
      "        logger.info(\"Training complete\")\n",
      "    \n",
      "    def evaluate(self, X_test: np.ndarray, y_test: np.ndarray) -> dict:\n",
      "        \"\"\"\n",
      "        Evaluate the model on test data.\n",
      "        \n",
      "        Args:\n",
      "            X_test: Test features\n",
      "            y_test: Test targets\n",
      "            \n",
      "        Returns:\n",
      "            Dictionary of evaluation metrics\n",
      "        \"\"\"\n",
      "        logger.info(\"Evaluating model...\")\n",
      "        \n",
      "        # Scale features\n",
      "        X_test_scaled = self.scaler.transform(X_test)\n",
      "        \n",
      "        # TODO: Add evaluation metrics\n",
      "        metrics = {}\n",
      "        \n",
      "        logger.info(f\"Evaluation complete: {metrics}\")\n",
      "        return metrics\n",
      "\n",
      "\n",
      "def main():\n",
      "    \"\"\"\n",
      "    Main execution function.\n",
      "    \"\"\"\n",
      "    logger.info(\"Starting ML pipeline\")\n",
      "    \n",
      "    # Initialize pipeline\n",
      "    pipeline = MLPipeline(random_state=42)\n",
      "    \n",
      "    # TODO: Add your workflow here\n",
      "    # Example:\n",
      "    # df = pipeline.load_data('data/dataset.csv')\n",
      "    # X, y = pipeline.preprocess_data(df, target_col='target')\n",
      "    # X_train, X_test, y_train, y_test = pipeline.split_data(X, y)\n",
      "    # pipeline.train(X_train, y_train)\n",
      "    # metrics = pipeline.evaluate(X_test, y_test)\n",
      "    \n",
      "    logger.info(\"Pipeline execution complete\")\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "\n",
      "### 3. **README.md** - Reflecting your interests\n",
      "```markdown\n",
      "# Machine Learning Project Template\n",
      "\n",
      "## Project Code: ALPHA-2024-ML\n",
      "\n",
      "A clean, modular machine learning project template designed for rapid experimentation and production-ready ML workflows.\n",
      "\n",
      "## 🎯 Project Overview\n",
      "\n",
      "This template provides a structured approach to machine learning projects with emphasis on:\n",
      "- Clean, maintainable code\n",
      "- Reproducible experiments\n",
      "- Modular pipeline architecture\n",
      "- Best practices for ML development\n",
      "\n",
      "## 🧠 Features\n",
      "\n",
      "- **Flexible ML Pipeline**: Modular `MLPipeline` class for easy customization\n",
      "- **Data Processing**: Built-in preprocessing and data splitting utilities\n",
      "- **Logging**: Comprehensive logging for debugging and monitoring\n",
      "- **Type Hints**: Full type annotations for better code clarity\n",
      "- **Scalability**: Easily extendable architecture\n",
      "\n",
      "## 🚀 Getting Started\n",
      "\n",
      "### Prerequisites\n",
      "\n",
      "- Python 3.8+\n",
      "- VSCode (recommended)\n",
      "\n",
      "### Installation\n",
      "\n",
      "1. Clone this repository\n",
      "2. Create a virtual environment:\n",
      "   ```bash\n",
      "   python -m venv venv\n",
      "   source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n",
      "   ```\n",
      "3. Install dependencies:\n",
      "   ```bash\n",
      "   pip install -r requirements.txt\n",
      "   ```\n",
      "\n",
      "### Usage\n",
      "\n",
      "```python\n",
      "python main.py\n",
      "```\n",
      "\n",
      "## 📁 Project Structure\n",
      "\n",
      "```\n",
      ".\n",
      "├── main.py              # Main pipeline implementation\n",
      "├── requirements.txt     # Project dependencies\n",
      "├── README.md           # This file\n",
      "├── data/               # Data directory (create as needed)\n",
      "├── models/             # Saved models (create as needed)\n",
      "├── notebooks/          # Jupyter notebooks for exploration\n",
      "└── tests/              # Unit tests\n",
      "```\n",
      "\n",
      "## 🔧 Customization\n",
      "\n",
      "The `MLPipeline` class is designed to be easily extended. Simply:\n",
      "\n",
      "1. Add your model initialization in the `train()` method\n",
      "2. Implement custom preprocessing in `preprocess_data()`\n",
      "3. Add evaluation metrics in the `evaluate()` method\n",
      "\n",
      "## 📊 Core Libraries\n",
      "\n",
      "This project leverages:\n",
      "- **NumPy**: Numerical computing\n",
      "- **Pandas**: Data manipulation and analysis\n",
      "- **Scikit-learn**: Machine learning algorithms and utilities\n",
      "\n",
      "## 🧪 Development\n",
      "\n",
      "### Code Quality\n",
      "\n",
      "Format code with Black:\n",
      "```bash\n",
      "black main.py\n",
      "```\n",
      "\n",
      "Run tests:\n",
      "```bash\n",
      "pytest tests/\n",
      "```\n",
      "\n",
      "Lint code:\n",
      "```bash\n",
      "flake8 main.py\n",
      "```\n",
      "\n",
      "## 💡 Ideas for Extension\n",
      "\n",
      "- Add support for deep learning frameworks (TensorFlow/PyTorch)\n",
      "- Implement experiment tracking (MLflow, Weights & Biases)\n",
      "- Add memory-efficient data loading for large datasets\n",
      "- Create a configuration system for hyperparameters\n",
      "- Build a simple web API for model serving\n",
      "\n",
      "## 📝 Notes\n",
      "\n",
      "This template emphasizes clarity and modularity, making it easy to understand, modify, and extend for various ML tasks.\n",
      "\n",
      "## 🔗 Related Interests\n",
      "\n",
      "- LLM memory systems\n",
      "- AI assistant architectures\n",
      "- Reproducible ML workflows\n",
      "\n",
      "---\n",
      "\n",
      "*Built with Python and ❤️ for clean machine learning*\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## ✅ Summary\n",
      "\n",
      "I've created a complete ML project structure based on your profile:\n",
      "\n",
      "1. **requirements.txt**: Includes your favorite libraries (numpy, pandas, scikit-learn) plus useful additions for ML development\n",
      "2. **main.py**: Clean, well-documented code with:\n",
      "   - Type hints throughout\n",
      "   - Comprehensive logging\n",
      "   - Modular `MLPipeline` class\n",
      "   - Clear separation of concerns\n",
      "3. **README.md**: Professional documentation that:\n",
      "   - References your project code (ALPHA-2024-ML)\n",
      "   - Highlights your core libraries\n",
      "   - Mentions your interest in LLM memory systems\n",
      "   - Includes practical setup instructions\n",
      "\n",
      "The code follows Python best practices with clear docstrings, type annotations, and a modular architecture that's easy to extend. You can copy these files directly into your new project directory and start building!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PRACTICAL DEMO: Personalized ML Project Setup\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Claude Sonnet 4.5 will use all stored memories to create a personalized project\n",
    "conversation_final = chat_with_claude(\n",
    "    \"Based on everything you know about me, create a project structure \"\n",
    "    \"for a new machine learning project. Include a requirements.txt with \"\n",
    "    \"my preferred libraries, a main.py template with my coding style, \"\n",
    "    \"and a README that reflects my interests.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📦 Final Memory Store State\n",
      "============================================================\n",
      "\n",
      "Total memories created: 2\n",
      "\n",
      "Memory contents:\n",
      "\n",
      "[user_profile.txt]\n",
      "  USER PROFILE\n",
      "  ============\n",
      "\n",
      "[secret_codes.txt]\n",
      "  SECRET PROJECT CODES\n",
      "  ====================\n"
     ]
    }
   ],
   "source": [
    "# Final memory state\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📦 Final Memory Store State\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal memories created: {len(memory_store)}\")\n",
    "print(\"\\nMemory contents:\")\n",
    "for key, value in memory_store.items():\n",
    "    print(f\"\\n[{key}]\")\n",
    "    content = value.get('content', '')\n",
    "    if content:\n",
    "        # Show first few lines\n",
    "        lines = content.split('\\n')[:3]\n",
    "        for line in lines:\n",
    "            if line.strip():\n",
    "                print(f\"  {line[:70]}...\" if len(line) > 70 else f\"  {line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Claude Sonnet 4.5's Native Memory** - The model has built-in memory capabilities\n",
    "2. **Persistence** - Memories persist across completely new chat sessions\n",
    "3. **Minimal Client Code** - Only need to handle tool use/result exchange\n",
    "4. **Personalization** - Claude Sonnet 4.5 uses memories to provide tailored responses\n",
    "5. **Dynamic Updates** - Memories can be updated as information changes\n",
    "\n",
    "The key insight: Claude Sonnet 4.5 manages its own memory system - the client just needs to provide a simple storage layer for the tool results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
