{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing Context with PDFs: Strategies for Amazon Bedrock Users\n",
    "\n",
    "- [Introduction](#introduction)\n",
    "- [Setup](#setup)\n",
    "- [Method 1: Using Bedrock DocumentBlock API](#method-1-using-bedrock-documentblock-api)\n",
    "- [Method 2: Using Amazon Bedrock Knowledge Bases](#method-2-using-amazon-bedrock-knowledge-bases)\n",
    "- [Method 3: Using Anthropic Native PDF Support](#method-3-using-anthropic-native-pdf-support)\n",
    "- [Method 4: Self-Managed PDF Processing](#method-4-self-managed-pdf-processing)\n",
    "- [Conclusion](#conclusion)\n",
    "- [Cleanup](#Cleanup)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "When working with large language models like Anthropic's Claude in Amazon Bedrock, providing relevant context is crucial for generating accurate, contextual responses. Often, this contextual information is contained in PDFs - whether they're business documents, reports, invoices, or other materials. This notebook explores four different methods of incorporating PDF content into your prompts for Claude and other Bedrock models, each with its own advantages and use cases.\n",
    "\n",
    "We'll work with a sample 2-page hotel bill PDF from [this](https://github.com/JensWalter/my-receipts/) public domain dataset. As we explore each method, we'll demonstrate its implementation, highlight its strengths and limitations, and show how Claude responds with the context provided.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Let's start by setting up our environment and importing the necessary libraries. We'll also define helper functions to interact with Claude through the Amazon Bedrock API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt -qU --disable-pip-version-check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This installs CLI utils for PDF processing, needed by pdf2image. On MacOS poppler can be installed with `brew install poppler`, on Linux you can use your favorite package manager - if it's not apt, for example `yum -y install poppler-utils`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Linux distros that use APT\n",
    "!which apt-get && sudo apt-get -qq update && sudo apt-get -qqy install poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, time, json, uuid, base64\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from IPython.display import display, Image\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's setup some variables.\n",
    "\n",
    "**IMPORTANT:** Replace {INSERT-YOUR-S3-BUCKET} with your own S3 bucket name.\n",
    "The bucket will be used to store our sample PDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with your preferred region (pick a region where Amazon Bedrock provides access to Claude 3.7 Sonnet)\n",
    "region = \"us-west-2\"\n",
    "# Replace this with an existing S3 bucket of your choice in the region configured above\n",
    "bucket_name = \"nsmagt-textract\"\n",
    "# Our sample PDF file\n",
    "pdf_file_name = \"sample.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, we'll create the Bedrock client.\n",
    "\n",
    "**IMPORTANT:** For this to work, you should have enabled access to Sonnet 3.7 in the AWS console, under \"Amazon Bedrock -> Model access\", and have configured an AWS region where Claude 3.7 Sonnet is available, such as us-west-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Bedrock client\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=region\n",
    ")\n",
    "\n",
    "# Define the model ID for Claude\n",
    "model_id = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Included with this notebook is utility.py which provides a number of helper functions we'll load and use when we need them. They're there so they don't clutter up our notebook. Let's start by loading `get_completion`, a simple function to call Claude on our prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import get_completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now let's try a prompt to make sure our setup so far, works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_response = get_completion(\n",
    "    prompt=\"What is Amazon Bedrock?\", \n",
    "    system_prompt=\"You are a helpful AI assistant who provides CONCISE, accurate information about AWS services.\",\n",
    "    model_id=model_id,\n",
    "    bedrock_runtime=bedrock_runtime\n",
    ")\n",
    "\n",
    "print(test_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now let's upload our sample PDF to the S3 bucket so we can use it in our examples:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the utility function that uploads files to S3\n",
    "from utility import upload_to_s3\n",
    "\n",
    "# Upload the file\n",
    "upload_result = upload_to_s3(pdf_file_name, bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's take a quick look at the PDF to understand what we're working with:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the function to display pages from our PDF\n",
    "from utility import display_pdf_page\n",
    "\n",
    "# Display both pages\n",
    "print(\"Hotel bill - page 1\")\n",
    "display_pdf_page(pdf_file_name, 0)\n",
    "print(\"Hotel bill - page 2\")\n",
    "display_pdf_page(pdf_file_name, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, let's explore each method for incorporating PDFs into our Claude conversations.\n",
    "\n",
    "## Method 1: Using Bedrock DocumentBlock API\n",
    "\n",
    "The DocumentBlock API provides a direct approach to including document content in your prompts. It automatically extracts text (using OCR if needed) and passes it along with your user prompt, to give the model more complete context about the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Define a function to call Claude with our sample PDF as context, using the DocumentBlock API:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call Claude with our PDF for context with DocumentBlock API\n",
    "def get_completion_with_document(prompt, pdf_path, system_prompt=None, temperature=0.1, max_tokens=4000):\n",
    "    \"\"\"\n",
    "    Send a prompt to Claude with document context using DocumentBlock\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The user prompt\n",
    "        pdf_path (str): Path to the PDF file\n",
    "        system_prompt (str, optional): System prompt\n",
    "        temperature (float, optional): Controls randomness\n",
    "        max_tokens (int, optional): Maximum tokens in the response\n",
    "        \n",
    "    Returns:\n",
    "        str: Claude's response\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the PDF file as bytes\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_bytes = file.read()\n",
    "    \n",
    "    # Create the message with document content\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": prompt,\n",
    "            },\n",
    "            {\n",
    "                \"document\": {\n",
    "                    \"name\": \"sample\",\n",
    "                    \"format\": \"pdf\",\n",
    "                    \"source\": {\n",
    "                        \"bytes\": pdf_bytes\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }]\n",
    "    \n",
    "    # Create the request parameters\n",
    "    converse_params = {\n",
    "        \"modelId\": model_id,\n",
    "        \"messages\": messages,\n",
    "        \"inferenceConfig\": {\"maxTokens\": max_tokens, \"temperature\": temperature}\n",
    "    }\n",
    "    \n",
    "    # Add system prompt if provided\n",
    "    if system_prompt:\n",
    "        converse_params[\"system\"] = [{\"text\": system_prompt}]  # System needs to be a list of dictionaries\n",
    "    \n",
    "    try:\n",
    "        # Call the Converse API\n",
    "        response = bedrock_runtime.converse(**converse_params)\n",
    "        \n",
    "        # Extract the response\n",
    "        ai_message = response[\"output\"][\"message\"]\n",
    "        text_message = ai_message[\"content\"][0][\"text\"]\n",
    "        \n",
    "        return text_message\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error type: {type(e)}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A common use case for providing PDF-based context to language models, is to ask questions about the content of the document. Let's ask Claude some questions to determine how well Claude understands the context provided through the DocumentBlock API:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's ask some questions about the document using DocumentBlock\n",
    "questions = [\n",
    "    \"What was the check-in date of the hotel stay?\",\n",
    "    \"What was the total cost of occupancy tax for the stay?\",\n",
    "    \"Describe the hotel logo on the bill.\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    \n",
    "    answer = get_completion_with_document(\n",
    "        prompt=f\"Answer the following question based on the provided document: {question}\",\n",
    "        pdf_path=pdf_file_name,\n",
    "        system_prompt=\"You are a helpful assistant analyzing document content. Be concise and precise.\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works, and it's fast. It's not entirely accurate though:\n",
    "- The OCR performed has an issue due to imperfect scan quality - Claude gets the last occupancy tax line wrong most of the time, due to a slight crease in the paper\n",
    "- Claude cannot describe the hotel logo on the document\n",
    "- Claude gets the hotel name in the logo wrong as the OCR process provides it with an incorrect spelling, possibly due to the lighter color used for the logo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Pros and Cons of DocumentBlock API\n",
    "\n",
    "**Pros:**\n",
    "- Simple integration with a single API call\n",
    "- Provides the full document context to the model at once\n",
    "- No need to manage separate knowledge base infrastructure\n",
    "- Lower end-to-end latency compared to some other approaches\n",
    "\n",
    "**Cons:**\n",
    "- OCR quality depends on the underlying document quality\n",
    "- Doesn't provide visual context to Claude (images, tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Using Amazon Bedrock Knowledge Bases\n",
    "\n",
    "Amazon Bedrock Knowledge Bases provide a Retrieval-Augmented Generation (RAG) solution that allows you to upload documents (including PDFs) and then use this data to enhance model responses. The system automatically processes documents, chunks them, and creates embeddings for efficient retrieval when answering queries. More info in the [Knowledge Bases documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base.html).\n",
    "\n",
    "Let's set up a Knowledge Base and upload our sample PDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Bedrock Knowledge Base client\n",
    "bedrock_kb = boto3.client('bedrock-agent', region_name=region)\n",
    "s3 = boto3.client('s3', region_name=region)\n",
    "\n",
    "# Generate a unique name for our knowledge base\n",
    "kb_name = f\"hotel-docs-kb-{str(uuid.uuid4())[:8]}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell creates the Opensearch vector database takes a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions from utility.py, for creating the necessary infrastructure ->\n",
    "# Opensearch Serverless, and Bedrock KB\n",
    "from utility import (\n",
    "    create_bedrock_kb_execution_role,\n",
    "    create_opensearch_vector_store,\n",
    "    wait_for_kb_status\n",
    ")\n",
    "\n",
    "# Create the necessary IAM role for the Knowledge Base\n",
    "kb_role = create_bedrock_kb_execution_role(bucket_name=bucket_name, region=region)\n",
    "kb_role_arn = kb_role['Role']['Arn']\n",
    "print(f\"Created Knowledge Base execution role: {kb_role_arn}\")\n",
    "\n",
    "# Create an OpenSearch Serverless vector store for our Knowledge Base\n",
    "vector_store_id = create_opensearch_vector_store(region=region)\n",
    "print(f\"Created OpenSearch vector store with ID: {vector_store_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Knowledge Base using the OpenSearch vector store\n",
    "response = bedrock_kb.create_knowledge_base(\n",
    "    name=kb_name,\n",
    "    description=\"Knowledge base for hotel documentation\",\n",
    "    roleArn=kb_role_arn,\n",
    "    knowledgeBaseConfiguration={\n",
    "        'type': 'VECTOR',\n",
    "        'vectorKnowledgeBaseConfiguration': {\n",
    "            'embeddingModelArn': f'arn:aws:bedrock:{region}::foundation-model/amazon.titan-embed-text-v1'\n",
    "        }\n",
    "    },\n",
    "    storageConfiguration={\n",
    "        'type': 'OPENSEARCH_SERVERLESS',\n",
    "        'opensearchServerlessConfiguration': {\n",
    "            'collectionArn': f'arn:aws:aoss:{region}:{boto3.client(\"sts\").get_caller_identity()[\"Account\"]}:collection/{vector_store_id}',\n",
    "            # Add the required field mapping\n",
    "            'fieldMapping': {\n",
    "                'vectorField': 'vector_field',\n",
    "                'textField': 'text_field',\n",
    "                'metadataField': 'metadata'\n",
    "            },\n",
    "            # Add the required vector index name\n",
    "            'vectorIndexName': 'bedrock-kb-index'\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "knowledge_base_id = response['knowledgeBase']['knowledgeBaseId']\n",
    "print(f\"Created Knowledge Base with ID: {knowledge_base_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data source for our S3 bucket\n",
    "response = bedrock_kb.create_data_source(\n",
    "    knowledgeBaseId=knowledge_base_id,\n",
    "    name='hotel-bills',\n",
    "    description='Hotel bills',\n",
    "    dataSourceConfiguration={\n",
    "        'type': 'S3',\n",
    "        's3Configuration': {\n",
    "            'bucketArn': f'arn:aws:s3:::{bucket_name}',\n",
    "            'inclusionPrefixes': [pdf_file_name]\n",
    "        }\n",
    "    },\n",
    "    vectorIngestionConfiguration={\n",
    "        'chunkingConfiguration': {\n",
    "            'chunkingStrategy': 'FIXED_SIZE',\n",
    "            'fixedSizeChunkingConfiguration': {\n",
    "                'maxTokens': 300,\n",
    "                'overlapPercentage': 20\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "data_source_id = response['dataSource']['dataSourceId']\n",
    "print(f\"Created data source with ID: {data_source_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the ingestion job to process our PDF\n",
    "response = bedrock_kb.start_ingestion_job(\n",
    "    knowledgeBaseId=knowledge_base_id,\n",
    "    dataSourceId=data_source_id\n",
    ")\n",
    "\n",
    "ingestion_job_id = response['ingestionJob']['ingestionJobId']\n",
    "print(f\"Started ingestion job with ID: {ingestion_job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the Knowledge Base to be active and data to be ingested\n",
    "print(\"Waiting for Knowledge Base to be ready and data to be ingested...\")\n",
    "wait_for_kb_status(bedrock_kb, knowledge_base_id, 'ACTIVE')\n",
    "\n",
    "# Check ingestion job status\n",
    "def check_ingestion_status(kb_id, ds_id, job_id):\n",
    "    response = bedrock_kb.get_ingestion_job(\n",
    "        knowledgeBaseId=kb_id,\n",
    "        dataSourceId=ds_id,\n",
    "        ingestionJobId=job_id\n",
    "    )\n",
    "    return response['ingestionJob']['status']\n",
    "\n",
    "# Wait for ingestion to complete\n",
    "ingestion_status = check_ingestion_status(knowledge_base_id, data_source_id, ingestion_job_id)\n",
    "while ingestion_status in ['STARTING', 'IN_PROGRESS']:\n",
    "    print(f\"Ingestion status: {ingestion_status}. Waiting...\")\n",
    "    time.sleep(30)\n",
    "    ingestion_status = check_ingestion_status(knowledge_base_id, data_source_id, ingestion_job_id)\n",
    "\n",
    "print(f\"Ingestion completed with status: {ingestion_status}\")\n",
    "if ingestion_status == 'COMPLETE':\n",
    "    print(\"Knowledge Base is ready to use!\")\n",
    "else:\n",
    "    print(f\"Warning: Ingestion ended with status {ingestion_status}\")\n",
    "\n",
    "# Wait a bit longer for data processing, or retrieval results will still be empty\n",
    "print(f\"Waiting for ingestion results to process...\")\n",
    "time.sleep(30)\n",
    "print(f\"Knowledge Base is ready to be queried!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bedrock-agent-runtime client for querying the Knowledge Base\n",
    "bedrock_kb_runtime = boto3.client('bedrock-agent-runtime', region_name=region)\n",
    "\n",
    "def query_knowledge_base(query_text, kb_id, num_results=5):\n",
    "    \"\"\"\n",
    "    Query a Bedrock Knowledge Base\n",
    "    \n",
    "    Args:\n",
    "        query_text (str): The query text\n",
    "        kb_id (str): Knowledge Base ID\n",
    "        num_results (int): Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        dict: The query response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = bedrock_kb_runtime.retrieve(\n",
    "            knowledgeBaseId=kb_id,\n",
    "            retrievalQuery={\n",
    "                'text': query_text\n",
    "            },\n",
    "            retrievalConfiguration={\n",
    "                'vectorSearchConfiguration': {\n",
    "                    'numberOfResults': num_results\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        return response\n",
    "    except ClientError as e:\n",
    "        print(f\"Error querying Knowledge Base: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query Claude with knowledge base context\n",
    "def query_claude_with_kb(user_question, kb_id):\n",
    "    \"\"\"\n",
    "    Query Claude with context from a Knowledge Base\n",
    "    \n",
    "    Args:\n",
    "        user_question (str): The question to ask\n",
    "        kb_id (str): Knowledge Base ID\n",
    "        \n",
    "    Returns:\n",
    "        str: Claude's response\n",
    "    \"\"\"\n",
    "    # First retrieve relevant information from the Knowledge Base\n",
    "    kb_response = query_knowledge_base(user_question, kb_id)\n",
    "    \n",
    "    # Extract the retrieved passages\n",
    "    passages = []\n",
    "    if kb_response and 'retrievalResults' in kb_response:\n",
    "        for result in kb_response['retrievalResults']:\n",
    "            passages.append(result['content']['text'])\n",
    "    \n",
    "    # Construct the prompt with context\n",
    "    context = \"\\n\\n\".join(passages)\n",
    "    \n",
    "    prompt = f\"\"\"I need information from the provided context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {user_question}\n",
    "\n",
    "Please answer based only on the information in the context. If the context doesn't contain relevant information, please say so.\"\"\"\n",
    "    \n",
    "    # Get Claude's response\n",
    "    claude_response = get_completion(\n",
    "        prompt=prompt,\n",
    "        model_id=model_id,\n",
    "        bedrock_runtime=bedrock_runtime\n",
    "    )\n",
    "    \n",
    "    return claude_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's test it with our standard set of questions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test questions using the Knowledge Base context\n",
    "questions = [\n",
    "    \"What was the check-in date of the hotel stay?\",\n",
    "    \"What was the total cost of occupancy tax for the stay?\",\n",
    "    \"Describe the hotel logo on the bill.\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    answer = query_claude_with_kb(question, knowledge_base_id)\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(\"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG shines when retrieving context from a large collection of documents, but the context it retrieves is not as rich as with methods that use the full document for context. So here, results aren't great:\n",
    "- The Knowledge Base successfully retrieves the check-in date, as it's a discrete piece of information that can be pulled from a single context chunk\n",
    "- It has less success retrieving the occupancy tax numbers - these values are in different places in the PDF and are likely split across chunks - Claude tries to make the most of the provided context but it doesn't understand what it's receiving\n",
    "- We're using text-only RAG here, so there's no visual context shared to Claude for completing the logo task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Pros and Cons of Knowledge Bases\n",
    "\n",
    "**Pros:**\n",
    "- Automatically processes and indexes documents for efficient retrieval\n",
    "- Handles large document collections well\n",
    "- Managed service with minimal operational overhead\n",
    "\n",
    "**Cons:**\n",
    "- Context is not as rich - no formatting/layout information or visual context\n",
    "- Higher latency due to two-step process - retrieval (which includes running embedding models), then generation\n",
    "- Limited control over exactly how the documents are chunked and processed\n",
    "- Visual elements of PDFs are not considered in the retrieval\n",
    "- Not great for our use case of document chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Using Anthropic Native PDF Support\n",
    "\n",
    "Anthropic's Claude has native support for handling PDFs directly through the native API, hosted by Anthropic. PDF support on that API leverages Claude's multimodal capabilities to process PDF files, allowing it to understand both the content and visual layout of the document. It's been designed with our document chat use case in mind.\n",
    "\n",
    "This example will only work if you have an Anthropic API key. If you don't, that's fine, skip the next two code cells and review the pre-generated output below the second cell.\n",
    "\n",
    "Now let's create a function to use PDF support on Anthropic's API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "# AWS Secrets Manger is a great place to store external api keys securely\n",
    "# Or, just place it in the ANTHROPIC_API_KEY env variable\n",
    "if 'ANTHROPIC_API_KEY' in os.environ and os.environ['ANTHROPIC_API_KEY']:\n",
    "    api_key = os.environ['ANTHROPIC_API_KEY']\n",
    "else:\n",
    "    secrets_manager = boto3.client(\"secretsmanager\", region_name = region)\n",
    "    secret_name = \"anthropic\"\n",
    "\n",
    "    response = secrets_manager.get_secret_value(SecretId=secret_name)\n",
    "    secret_json = json.loads(response[\"SecretString\"])\n",
    "    api_key = secret_json[\"api_key\"]\n",
    "\n",
    "# Initialize the Anthropic client\n",
    "anthropic_client = anthropic.Anthropic(\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "# Function to call Claude with direct PDF support using Anthropic's native API\n",
    "def get_completion_with_anthropic_pdf(prompt, pdf_path, model=\"claude-3-7-sonnet-20250219\", max_tokens=4000):\n",
    "    \"\"\"\n",
    "    Send a prompt to Claude with a PDF file using Anthropic's native API\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The user prompt\n",
    "        pdf_path (str): Path to the PDF file\n",
    "        model (str): Anthropic model ID\n",
    "        max_tokens (int): Maximum tokens in the response\n",
    "        \n",
    "    Returns:\n",
    "        str: Claude's response\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read and encode the PDF file\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        pdf_data = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    \n",
    "    # Create the message with PDF content\n",
    "    try:\n",
    "        message = anthropic_client.messages.create(\n",
    "            model=model,\n",
    "            max_tokens=max_tokens,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"document\",\n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\",\n",
    "                                \"media_type\": \"application/pdf\",\n",
    "                                \"data\": pdf_data\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Extract the response text\n",
    "        return message.content[0].text\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Anthropic API: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's test it with our standard set of questions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's ask some questions using Anthropic's native PDF support\n",
    "questions = [\n",
    "    \"What was the check-in date of the hotel stay?\",\n",
    "    \"What was the total cost of occupancy tax for the stay?\",\n",
    "    \"Describe the hotel logo on the bill.\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    \n",
    "    answer = get_completion_with_anthropic_pdf(\n",
    "        prompt=f\"Answer the following question based on the provided PDF document: {question}\",\n",
    "        pdf_path=pdf_file_name\n",
    "    )\n",
    "    \n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude's answers are entirely accurate this way:\n",
    "- Claude finds the correct check-in date\n",
    "- The occupancy tax is correctly extracted and calculated\n",
    "- The logo is well-described and there are no problematic OCR outputs visible in the output\n",
    "\n",
    "Here's pre-generated output using the Anthropic native API (in case you don't have an Anthropic API key):\n",
    "```\n",
    "Question: What was the check-in date of the hotel stay?\n",
    "Answer: Based on the hotel invoice, the check-in date (arrival date) was April 7, 2019 (shown as 04-07-19 in the document). This information appears in the header section of the invoice from the Mystic Hotel in San Francisco.\n",
    "    -------------------------------------------------------------------\n",
    "Question: What was the total cost of occupancy tax for the stay?\n",
    "Answer: Based on the hotel invoice from Mystic Hotel, the total cost of occupancy tax for Jens Walter's stay from April 7-14, 2019 was the sum of the daily occupancy tax charges:\n",
    "\n",
    "$32.73 (April 7)\n",
    "$47.60 (April 8)\n",
    "$53.55 (April 9)\n",
    "$65.45 (April 10)\n",
    "$35.70 (April 11)\n",
    "$29.75 (April 12)\n",
    "$29.75 (April 13)\n",
    "\n",
    "This totals to $294.53 for the entire stay in occupancy tax.\n",
    "    -------------------------------------------------------------------\n",
    "Question: Describe the hotel logo on the bill.\n",
    "Answer: The hotel invoice shows the Mystic Hotel logo, which appears as a minimalist design with the letter \"m\" inside a circular element. The logo is displayed at the top of the invoice with \"MYSTIC HOTEL\" written below it in uppercase letters, followed by \"UNION SQUARE | SAN FRANCISCO\" indicating the hotel's location. The logo has a sleek, modern aesthetic that fits with the upscale nature of the hotel.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Pros and Cons of Anthropic Native PDF Support\n",
    "\n",
    "**Pros:**\n",
    "- Direct handling of PDF files without preprocessing\n",
    "- Provides Claude visual layout and formatting information\n",
    "- Single API call implementation\n",
    "- Multimodal capabilities - Claude understands tables, charts, and visual elements\n",
    "- Best accuracy for document chat due to the combination of high-performance text extraction with visual context\n",
    "- Fast\n",
    "\n",
    "**Cons:**\n",
    "- Not available on Amazon Bedrock today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 4: Self-Managed PDF Processing\n",
    "\n",
    "To implement a similar solution for document chat as method 3, but using Amazon Bedrock instead of the Anthropic native API, we can implement a self-managed solution that extracts both text and images from PDFs and provides them to Claude separately. This approach gives us flexibility in handling documents. The example can easily be adapted to only provide the context that Claude needs for a particular type of PDF source. For complex files with visual information as well as (scanned) text, we can send both modalities. If a document is text-only, we can only extract text. If the document is visual (like an image or diagram) we can only send Claude images. This way we optimize latency, input tokens, and complexity.\n",
    "\n",
    "First, let's define a function to extract text from our document using the AWS-managed text extraction service, Amazon Textract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import textract\n",
    "\n",
    "# Function to extract text from our PDF using Amazon Textract\n",
    "def extract_text_from_pdf(file_name, bucket_name):\n",
    "    \"\"\"\n",
    "    Extract text from a PDF file using AWS Textract\n",
    "    \n",
    "    Args:\n",
    "        file_name (str): Name of the PDF file\n",
    "        bucket_name (str): S3 bucket where the file is stored\n",
    "        \n",
    "    Returns:\n",
    "        str: Extracted text\n",
    "    \"\"\"\n",
    "    # Using the provided textract helper function\n",
    "    extracted_text = textract(file_name, bucket_name, region)\n",
    "    return extracted_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the function to extract text from our sample PDF. This will take a few minutes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = extract_text_from_pdf(pdf_file_name, bucket_name)\n",
    "\n",
    "# Print a sample of the extracted text\n",
    "print(f\"Extracted {len(extracted_text)} characters of text\")\n",
    "print(\"Sample of extracted text:\")\n",
    "print(extracted_text[:250] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now let's create a function to call Claude, with PDF pages converted to images using pdf2image, and the text extracted with Textract:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call Claude with both images and text\n",
    "def get_completion_with_images_and_text(prompt, pdf_path, bucket_name, system_prompt=None, temperature=0.0, max_tokens=2000):\n",
    "    \"\"\"\n",
    "    Send a prompt to Claude with both images and extracted text\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The user prompt\n",
    "        pdf_path (str): Path to the PDF file\n",
    "        bucket_name (str): S3 bucket name for Textract\n",
    "        system_prompt (str, optional): System prompt\n",
    "        temperature (float, optional): Controls randomness\n",
    "        max_tokens (int, optional): Maximum tokens in the response\n",
    "        \n",
    "    Returns:\n",
    "        str: Claude's response\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert PDF to images\n",
    "    images = convert_from_path(pdf_path)\n",
    "    \n",
    "    # Prepare content list with the prompt that includes extracted text\n",
    "    content_items = [\n",
    "        {\n",
    "            \"text\": f\"\"\"<extracted_text_context>\n",
    "{extracted_text}\n",
    "</extracted_text_context>\n",
    "\n",
    "{prompt}\"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "# Add each page image to the content\n",
    "    for i, img in enumerate(images):\n",
    "        # Convert PIL Image to bytes\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        img.save(img_byte_arr, format='PNG')\n",
    "        img_bytes = img_byte_arr.getvalue()\n",
    "\n",
    "        # Add raw bytes to content items\n",
    "        content_items.append({\n",
    "            \"image\": {\n",
    "                \"format\": \"png\", \n",
    "                \"source\": {\"bytes\": img_bytes}\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Set up the request parameters\n",
    "    inference_config = {\n",
    "        \"temperature\": temperature,\n",
    "        \"maxTokens\": max_tokens,\n",
    "        \"topP\": 0.9\n",
    "    }\n",
    "    \n",
    "    converse_params = {\n",
    "        \"modelId\": model_id,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": content_items}\n",
    "        ],\n",
    "        \"inferenceConfig\": inference_config\n",
    "    }\n",
    "    \n",
    "    if system_prompt:\n",
    "        converse_params[\"system\"] = [{\"text\": system_prompt}]\n",
    "    \n",
    "    try:\n",
    "        response = bedrock_runtime.converse(**converse_params)\n",
    "        text_content = response['output']['message']['content'][0]['text']\n",
    "        return text_content\n",
    "    except ClientError as err:\n",
    "        message = err.response['Error']['Message']\n",
    "        print(f\"A client error occurred: {message}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's test it with our standard set of questions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's ask some questions using both images and extracted text\n",
    "questions = [\n",
    "    \"What was the check-in date of the hotel stay?\",\n",
    "    \"What was the total cost of occupancy tax for the stay?\",\n",
    "    \"Describe the hotel logo on the bill.\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    \n",
    "    answer = get_completion_with_images_and_text(\n",
    "        prompt=f\"Answer the following question based on the provided hotel documentation: {question}\",\n",
    "        pdf_path=pdf_file_name,\n",
    "        bucket_name=bucket_name,\n",
    "        system_prompt=\"You are a helpful assistant analyzing document content. You have access to both the document text and images. Use both to provide accurate, detailed answers.\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is great. All the facts are correctly retrieved due to the combination of highly accurate text extraction with Textract, and visual context provided to Claude through pdf2image. Claude also shows great visual awareness of the layout and hotel logo. There's a bit of delay waiting for the Textract job to complete though, so depending on the use case this part of the context you can leave text extraction out, or some simpler means of text extraction can be implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Pros and Cons of Self-Managed PDF Processing\n",
    "\n",
    "**Pros:**\n",
    "- Comprehensive context, combining visual and textual information\n",
    "- High accuracy\n",
    "- Complete control over document processing, providing greatest flexibility for customization\n",
    "\n",
    "**Cons:**\n",
    "- Higher latency (especially when combining text extraction with sending Claude PDF pages as images)\n",
    "- More code to manage (complexity and higher operational burden)\n",
    "- May require additional services for text extraction\n",
    "- Higher token usage, which can increase costs\n",
    "- A maximum of 20 images (ie. PDF pages) can be included with each Bedrock request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We've explored four different methods for incorporating PDF content into conversations with Claude through Amazon Bedrock:\n",
    "\n",
    "1. **DocumentBlock API**: Provides a simpler, more direct way to include document content in your prompts. For quick context from simple documents, without needing additional infrastructure. Not great with OCR or using visual context such as tables or images. \n",
    "\n",
    "2. **Knowledge Bases**: Best for large document collections where you need to find relevant information across multiple documents. Offers scalable, managed infrastructure with semantic search capabilities, but the model has less context to work with per request than other methods and is therefore not ideal for situations where we need the full context from 1 or a few documents (such as our document chat scenario.\n",
    "\n",
    "3. **Anthropic Native PDF Support**: High accuracy, scalability (up to 100 page PDF files) and simplicity, but not available on Amazon Bedrock currently.\n",
    "\n",
    "4. **Self-Managed PDF Processing**: Offers great flexibility, accuracy and control by separately handling text extraction and image processing. Best for complex documents where precise control over processing is needed, but scalability is less than Anthropic's native PDF support.\n",
    "\n",
    "The best method for your use case will depend on factors like:\n",
    "\n",
    "- The number and size of documents you need to process\n",
    "- Whether visual layout is important\n",
    "- Your latency and cost requirements\n",
    "- The complexity of information retrieval needed\n",
    "\n",
    "By understanding these different approaches, you can choose the most appropriate method to enhance Claude's abilities with document context, leading to more accurate and helpful responses for your specific use cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Don't forget to remove the persistent configurations we've created in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup all AWS resources created in this notebook\n",
    "print(\"Starting cleanup of AWS resources...\")\n",
    "\n",
    "# 1. Delete the Knowledge Base\n",
    "try:\n",
    "    print(f\"Deleting Knowledge Base {knowledge_base_id}...\")\n",
    "    bedrock_kb.delete_knowledge_base(knowledgeBaseId=knowledge_base_id)\n",
    "    print(\"Knowledge Base deleted successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting Knowledge Base: {e}\")\n",
    "\n",
    "# 2. Delete the OpenSearch Serverless collection\n",
    "try:\n",
    "    # First get the collection details to get the name\n",
    "    aoss = boto3.client('opensearchserverless', region_name=region)\n",
    "    response = aoss.batch_get_collection(ids=[vector_store_id])\n",
    "    collection_name = response['collectionDetails'][0]['name']\n",
    "    \n",
    "    # Delete the collection\n",
    "    print(f\"Deleting OpenSearch collection {vector_store_id}...\")\n",
    "    aoss.delete_collection(id=vector_store_id)\n",
    "    print(\"OpenSearch collection deletion initiated\")\n",
    "    \n",
    "    # Delete the security policies\n",
    "    print(\"Deleting OpenSearch security policies...\")\n",
    "    \n",
    "    # Get policy names based on collection name\n",
    "    encryption_policy_name = f\"{collection_name}-enc\"\n",
    "    network_policy_name = f\"{collection_name}-network\"\n",
    "    access_policy_name = f\"{collection_name}-access\"\n",
    "    \n",
    "    # Delete policies\n",
    "    try:\n",
    "        aoss.delete_security_policy(name=encryption_policy_name, type='encryption')\n",
    "        print(f\"Deleted encryption policy {encryption_policy_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting encryption policy: {e}\")\n",
    "        \n",
    "    try:\n",
    "        aoss.delete_security_policy(name=network_policy_name, type='network')\n",
    "        print(f\"Deleted network policy {network_policy_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting network policy: {e}\")\n",
    "    \n",
    "    # Delete access policy - according to the docs, this also needs a type parameter\n",
    "    try:\n",
    "        aoss.delete_access_policy(name=access_policy_name, type='data')\n",
    "        print(f\"Deleted access policy {access_policy_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting access policy: {e}\")\n",
    "    \n",
    "    print(\"OpenSearch security policies deletion completed\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting OpenSearch resources: {e}\")\n",
    "\n",
    "# 3. Delete the IAM roles\n",
    "try:\n",
    "    iam = boto3.client('iam')\n",
    "    \n",
    "    # Get the role name from the ARN\n",
    "    kb_role_name = kb_role_arn.split('/')[-1]\n",
    "    \n",
    "    # First detach all policies\n",
    "    print(f\"Deleting IAM role policies for {kb_role_name}...\")\n",
    "    \n",
    "    # List and delete inline policies\n",
    "    inline_policies = iam.list_role_policies(RoleName=kb_role_name)\n",
    "    for policy_name in inline_policies.get('PolicyNames', []):\n",
    "        iam.delete_role_policy(RoleName=kb_role_name, PolicyName=policy_name)\n",
    "    \n",
    "    # Delete the role\n",
    "    print(f\"Deleting IAM role {kb_role_name}...\")\n",
    "    iam.delete_role(RoleName=kb_role_name)\n",
    "    print(\"IAM role deleted successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting IAM role: {e}\")\n",
    "\n",
    "print(\"Cleanup completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
